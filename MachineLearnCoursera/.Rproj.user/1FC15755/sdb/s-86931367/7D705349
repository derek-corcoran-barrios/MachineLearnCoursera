{
    "contents" : "---\ntitle: \"Human Activity Recognition Unilateral Dumbbell Biceps Curl\"\nauthor: \"Derek Corcoran\"\ndate: \"Monday, June 15, 2015\"\noutput: pdf_document\n---\n\n# **Human Activity Recognition Unilateral Dumbbell Biceps Curl**\n\n### Summary\n\nThe objective of this project is to predict weather a Dumbbell Biceps Curl was properly executed. In order to do that, a machine learning algorithm will be used to predict when the exercise  was properly done (*Class A*), or if they made a mistake (*Class B to E*), our Data set consists of the information given by sensors attached to the body and/or dumbbell while the exercise  was done, and it was classified by a human (Personal Trainer).\n\n### Data manipulation and training\n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nlibrary(ggplot2)\nlibrary(caret)\n```\n\nThe first thing we do is to load the training data and divide it. Usually 60% of it would be used as a training set, and 40% as a test set, but since this is a test, we will use 15% as training and 85% as testing for the validation of the dataset. \n\n```{r, cache=TRUE, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(caret)\npml.training <- read.csv(\"~/Coursera/specialization R data/Machine Learning/Week3/pml-training.csv\")\npml.testing <- read.csv(\"~/Coursera/specialization R data/Machine Learning/Week3/pml-testing.csv\")\nset.seed(7)\n#create datapartition 60% Training 40 % test\ninTrain = createDataPartition(pml.training$classe, p = 0.15,list=FALSE)\ntraining = pml.training[inTrain,]\ntesting = pml.training[-inTrain,]\nresult.train<-training$classe\nresult.test<-testing$classe\n```\n\nThe full dataset had `r length(pml.training$classe)` observation, of which `r length (training$classe)` was use to train the model and `r length (testing$classe)` was used to test the model, also we have a dataset of `r length(pml.testing[,1])` to which we don't know the answer to, which will be used later for further tests.\n\nWe start with `r length(training[,-160])`, but we remove timestamps and we also preprocess the data by removing the near zero variable ones, and also remove all the columns with more than 50% NA. *I will keep the username as a variable, but I will transform it into a dummy variable.* \n\n```{r, echo=FALSE,message=FALSE,warning=FALSE}\n#dummies<-dummyVars(classe~user_name,data=training)\n#dummy.var.training<-predict(dummies, newdata=training)\n#dummy.var.testing<-predict(dummies,newdata=testing)\n#dummy.var.quiz<-predict(dummies, newdata=pml.testing)\n\n#remove variables with near zero variability\n\nnsv<-nearZeroVar(training[,-160], saveMetrics=TRUE)\npredictors.train<-training[,-160]\npredictors.test<- testing[,-160]\n\npredictors.train<-predictors.train[nsv$nzv==FALSE]\npredictors.test<-predictors.test[nsv$nzv==FALSE]\npml.testing <- pml.testing[nsv$nzv==FALSE]\n\npredictors.train<-predictors.train[,-1]\npredictors.test<-predictors.test[,-1]\npml.testing <- pml.testing[,-1]\n#remove timestamps and user names (will be replaced by dummy variables for usernames)\n\npredictors.train<-predictors.train[,-(1:4)]\npredictors.test<-predictors.test[,-(1:4)]\npml.testing <- pml.testing[,-(1:4)]\n#dummies<-dummyVars(classe~user_name,data=training)\n#dummy.var.training<-predict(dummies, newdata=training)\n#dummy.var.testing<-predict(dummies,newdata=testing)\n#dummy.var.quiz<-predict(dummies, newdata=pml.testing)\n#predictors.train<-cbind(predictors.train,dummy.var.training)\n#predictors.test<-cbind(predictors.test,dummy.var.testing)\n#pml.testing<-cbind(pml.testing, dummy.var.quiz)\n\n#remove the columns with more than 50% of NA\npredictors.train<-predictors.train[,colSums(is.na(predictors.train))<nrow(predictors.train)*0.5]\npredictors.test<-predictors.test[,colSums(is.na(predictors.train))<nrow(predictors.train)*0.5]\npml.testing<-pml.testing[,colSums(is.na(predictors.train))<nrow(predictors.train)*0.5]\n\ntraining<-cbind(result.train, predictors.train)\ntesting<-cbind(result.test, predictors.test)\n```\n\nThe number of variables ends up being `r length(predictors.train)`.\n\nLets explore the Variables\n\n\n```{r, cache=TRUE, echo=FALSE}\npairs(training[,2:12],pch = 21, bg = c(1:5)[unclass(training[,1])])\npairs(training[,13:23],pch = 21, bg = c(1:5)[unclass(training[,1])])\npairs(training[,24:34],pch = 21, bg = c(1:5)[unclass(training[,1])])\nsummary(training)\n```\n\n```{r, cache=TRUE, echo=FALSE}\npairs(training[,1:40],pch = 21, bg = c(1:5)[unclass(training[,1])])\n```\n\n# model\n\nnow lets build the model\n\n```{r,echo=FALSE,cache=TRUE}\ncolnames(training)[1] <- \"classe\"\n\nmodelFit<-train(classe ~.,data=training)\n```\n\n\nThen lets check the model\n\n```{r}\nmodelFit\nmodelFit$finalModel\n```\n\n```{r}\ncolnames(testing)[1] <- \"classe\"\npredictions <- predict(modelFit,newdata=testing)\nconfusionMatrix(predictions, testing[,1])\n```\n\n```{r}\npredictions.final <- predict(modelFit,newdata=pml.testing)\npredictions.final\nlength(predictions.final)\n\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\npml_write_files(predictions.final)\n```\n",
    "created" : 1434826561092.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1789435383",
    "id" : "7D705349",
    "lastKnownWriteTime" : 1434826617,
    "path" : "C:/Users/usuario/MachineLearnCoursera/MachineLearn.Rmd",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled2"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}